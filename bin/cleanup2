#!/usr/bin/env perl

#
# jobcenter cleanup
# (file based version)
#
# archives old jobs in a file after:
# - 1 month for jobs_archive
# - 3 monhts for jobs (this keeps full error information around a bit longer)
# - or longer if any of the called actions has a archive policy
#
# the job_task_log for archived jobs is deleted
#

use strict;
use warnings;
use 5.10.0;

# standard modules
use Cwd qw(realpath);
use Data::Dumper;
use FindBin;
use Getopt::Long;
use Time::Piece;

# cpan
use Config::Tiny;
use DBI;
use DBD::Pg;

# potentially useful globals
my $cfg;
my $debug = 0;

exit main(@ARGV);

sub main {
	my $cfgpath = realpath("$FindBin::Bin/../etc/jobcenter.conf");
	my $count = 1;

	GetOptions(
		'config=s' => \$cfgpath,
		'count!' => \$count,
		'debug!', => \$debug,
	) or die "Error in command line arguments\n";
	#my ($job_id) = @_;

	$cfg = Config::Tiny->read($cfgpath);
	die 'failed to read config ' . $cfgpath . ': ' . Config::Tiny->errstr unless $cfg;

	my $pgdsn = 'dbi:Pg:dbname=' . $cfg->{pg}->{db}
		. (($cfg->{pg}->{host}) ? ';host=' . $cfg->{pg}->{host} : '')
		. (($cfg->{pg}->{port}) ? ';port=' . $cfg->{pg}->{port} : '');
	my $pguser = $cfg->{admin}->{user};
	my $pgpass = $cfg->{admin}->{pass};

	# make our clientname the application_name visible in postgresql
	$ENV{'PGAPPNAME'} = "$0 [$$]";

	my $pgh = DBI->connect(
		$pgdsn, $pguser, $pgpass,
		{
			AutoCommit => 1,
			RaiseError => 1,
			PrintError => 1,
		}
	) or die "cannot connect to db: $DBI::errstr";
	#$pgh->{FetchHashKeyName} = 'NAME_lc';
	$pgh->{pg_placeholder_dollaronly} = 1;

	my $jobsq = $pgh->prepare(<<'EOT');
select
	job_id, job_finished
from
	jobs p
where
	job_id > $1
	and job_finished < now() - interval '3 months'
	and not exists (
		select
			true
		from
			jobs c
		where
			c.parentjob_id=p.job_id
		limit 1
	)
order by
	job_id
limit
	1000
EOT

	my $jobsarchiveq = $pgh->prepare(<<'EOT');
select
	job_id, job_finished
from
	jobs_archive p
where
	job_id > $1
	and job_finished < now() - interval '1 months'
order by
	job_id
limit
	1000
EOT

=pod
	my $purgeq = $pgh->prepare(<<'EOT');
-- $1 job_id
-- $2 job_finished
select
	-- return a perlish true or false
	case when $2::date < now()
		- max( coalesce( (actions.config ->> 'archive'), '1 month' )::interval )
	then
		1
	else
		0
	end as purge
from
	job_task_log
	join tasks using (workflow_id, task_id)
	join actions using (action_id)
where
	job_id = $1
EOT
=cut

	my $deljobarch = $pgh->prepare(<<'EOT');
delete from
	jobs_archive
where
	job_id = $1
returning
	to_char(job_created, 'YYYY-MM-DD'),
	jsonb_pretty(row_to_json(jobs_archive)::jsonb)
EOT

	my $deljob = $pgh->prepare(<<'EOT');
delete from
	jobs
where
	job_id = $1
returning
	to_char(job_created, 'YYYY-MM-DD'),
	jsonb_pretty(row_to_json(jobs)::jsonb)
EOT

	my $deltasks = $pgh->prepare(<<'EOT');
delete from
	job_task_log
where
	job_id = $1
EOT

	my ($last_job_id, $j);
	my ($jap, $jak, $jp, $jk) = (0, 0, 0, 0);

	say 'cleaning up jobs_archive table';

	$last_job_id = 0;

	while (1) {
		say "batch starting at: $last_job_id" if $debug;

		$jobsarchiveq->execute($last_job_id);
		my $jobs = $jobsarchiveq->fetchall_arrayref();

		last unless $jobs and @$jobs;

		for my $j (@$jobs) {
			($last_job_id) = @$j;

			#say "last_job_id: $last_job_id";

			#$purgeq->execute(@$j);
			#my ($purge) = $purgeq->fetchrow_array();

			#unless ($purge) {
			#	say "skipping $last_job_id" if $debug;
			#	$jak++;
			#	next;
			#}

			say "need to purge $last_job_id" if $debug;
			$jap++;
			
			$pgh->begin_work();
			$deltasks->execute($last_job_id);
			$deljobarch->execute($last_job_id);
			my ($ds, $job) = $deljobarch->fetchrow_array();
			#$deljobarch->finish();
			$pgh->commit();

			archprint($ds, $job);
		}
	}

	if ($count) {
		say "purged from jobs_archive: $jap";
		#say "    kept in jobs_archive: $jak";
	}

	say 'cleaning up jobs table';

	$last_job_id = 0;

	while (1) {
		say "batch starting at: $last_job_id" if $debug;

		$jobsq->execute($last_job_id);
		my $jobs = $jobsq->fetchall_arrayref();

		last unless $jobs and @$jobs;

		for my $j (@$jobs) {
			($last_job_id) = @$j;

			#say "last_job_id: $last_job_id";

			#$purgeq->execute(@$j);
			#my ($purge) = $purgeq->fetchrow_array();

			#unless ($purge) {
			#	say "skipping $last_job_id" if $debug;
			#	$jk++;
			#	next;
			#}

			say "need to purge $last_job_id" if $debug;
			$jp++;
			
			$pgh->begin_work();
			$deltasks->execute($last_job_id);
			$deljob->execute($last_job_id);
			my ($ds, $job) = $deljob->fetchrow_array();
			#$deljob->finish();
			$pgh->commit();

			archprint($ds, $job);
		}
	}

	# make vacuum less agressive almost like autovacuum
	# (autovacuum uses 20)
	$jdb->do('set vacuum_cost_delay=10');
	# reclaim space
	$pgh->do('vacuum analyze jobs');
	$pgh->do('vacuum analyze jobs_archive');
	$pgh->do('vacuum analyze job_task_log');

	if ($count) {
		say "        purged from jobs: $jp";
		#say "            kept in jobs: $jk";
	}

	return 0;
}

sub archprint {
	use bytes;
	my ($ds, $o) = @_;
	state $ods = '';
	state $af;
	if ($ds ne $ods) {
		my $fn = $cfg->{cleanup}->{archivepath} . "/cleanup.$ds.xz";
		close($af) if $af;
		open($af, '|-', "xz - >> $fn") or
			die "could not open archive file $fn for writing: $!";
		$ods = $ds;
	}
	
	printf $af "%u:\n%s\n\n", length($o)+2, $o;
}

